{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fca2961-2954-4c04-8c8c-39eea1cfe5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_db(save_df: DataFrame, table_name: str, mode=\"overwrite\"):\n",
    "    save_df.write.format(\"jdbc\") \\\n",
    "        .mode(mode) \\\n",
    "        .option(\"url\", \"jdbc:mysql://127.0.0.1:3306/cs179g\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"dbtable\", f\"{table_name}\") \\\n",
    "        .option(\"user\", \"group6\") \\\n",
    "        .option(\"batchsize\", \"100000\") \\\n",
    "        .option(\"password\", \"grp6\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984a2dc5-1591-4cf2-8db0-935c1eb6c935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ubuntu/your_venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "mysql#mysql-connector-java added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4c75795e-254a-4752-86ca-b426f529b297;1.0\n",
      "\tconfs: [default]\n",
      "\tfound mysql#mysql-connector-java;8.0.30 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.19.4 in central\n",
      ":: resolution report :: resolve 165ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;3.19.4 from central in [default]\n",
      "\tmysql#mysql-connector-java;8.0.30 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4c75795e-254a-4752-86ca-b426f529b297\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/5ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/25 07:31:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/25 07:31:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/25 07:31:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157161\n",
      "123593\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import explode, udf, size, col, concat_ws, to_date, to_timestamp, date_trunc, count, array_contains, month, dayofmonth, hour, explode_outer, split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.appName('practice').config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.30').master(\n",
    "    \"local\").getOrCreate()\n",
    "\n",
    "mdhr_tags = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost:3306/cs179g\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"mdhr_tags\") \\\n",
    "    .option(\"user\", \"Garrett\").option(\"password\", \"123\").load()\n",
    "\n",
    "mdhr_tags.filter(col('month') != 10).count()\n",
    "\n",
    "exploded_tags = mdhr_tags.withColumn('tags',split(col('tags'),','))\n",
    "\n",
    "exploded_tags = exploded_tags.withColumn('tags',explode_outer('tags'))\n",
    "\n",
    "exploded_tags=exploded_tags.filter(col('tags') != '')\n",
    "\n",
    "print(exploded_tags.count())\n",
    "print(exploded_tags.filter(col('tags') != col('tickers')).count())\n",
    "\n",
    "exploded_tags = exploded_tags.filter(col('tags') != col('tickers'))\n",
    "\n",
    "exploded_tags.createOrReplaceTempView(\"exploded_tags\")\n",
    "top_tags=spark.sql(\"Select tickers, month, day, hour,tags, count(tags) as times from exploded_tags group by tickers,month, day, hour,tags order by times DESC\")\n",
    "top_tags.createOrReplaceTempView(\"top_tags\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17694a0-3033-4fe0-b245-ddd0d867e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---+----+------------+-----+\n",
      "|tickers|month|day|hour|        tags|times|\n",
      "+-------+-----+---+----+------------+-----+\n",
      "|   META|   11|  3|  12|     ARWEAVE|  375|\n",
      "|   TEAM|   10| 26|   8|        DEFI|  329|\n",
      "|   TEAM|   10| 26|   8|       SAFUU|  256|\n",
      "|   TEAM|   10| 26|   8|       GRAPE|  256|\n",
      "|   TEAM|   10| 26|   8|  STABLEFUND|  256|\n",
      "|   TEAM|   10| 26|   8|         EMP|  256|\n",
      "|   TEAM|   10| 26|   8|        DRIP|  256|\n",
      "|   TEAM|   10| 26|   8|     CAPTAIN|  255|\n",
      "|     EA|   10| 26|  16|          FX|  223|\n",
      "|     EA|   11|  3|  17|          FX|  220|\n",
      "|   TEAM|   10| 26|  11|        DEFI|  188|\n",
      "|   TEAM|   10| 26|   8|  JOINTAKEDA|  181|\n",
      "|   TEAM|   10| 26|   8|BATTLESTAKES|  181|\n",
      "|   META|   11|  3|  13|     ARWEAVE|  171|\n",
      "|   TEAM|   10| 26|  11|         EMP|  167|\n",
      "|   TEAM|   10| 26|  11|  STABLEFUND|  167|\n",
      "|   TEAM|   10| 26|  11|       GRAPE|  167|\n",
      "|   TEAM|   10| 26|  11|     CAPTAIN|  167|\n",
      "|   TEAM|   10| 26|  11|       SAFUU|  167|\n",
      "|   TEAM|   10| 26|  11|        DRIP|  167|\n",
      "+-------+-----+---+----+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_tags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613ccd59-c071-4493-ab03-8c75880b4a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "write_db(top_tags, 'top_tags')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
